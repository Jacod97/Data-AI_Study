{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT(Speech to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SpeechRecognition pyaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îì£Îäî Ï§ë....\n",
      "User: ÏïàÎÖïÌïòÏÑ∏Ïöî\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Îì£Îäî Ï§ë....\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    audio = recognizer.listen(source)\n",
    "    try:\n",
    "        audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "        print(f\"User: {audio_text}\")\n",
    "    except Exception as e:\n",
    "        print(\"Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS(Text to Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: ÏïàÎÖïÌïòÏÑ∏Ïöî Î∞òÍ∞ëÏäµÎãàÎã§Îã§\n"
     ]
    }
   ],
   "source": [
    "# pip install pyttsx3\n",
    "import pyttsx3 \n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # ÎßêÌïòÎäî ÏÜçÎèÑ Ï°∞Ï†à\n",
    "engine.setProperty(\"volume\", 2.0) # Î≥ºÎ•®(1.0 - 100%)\n",
    "\n",
    "text = \"ÏïàÎÖïÌïòÏÑ∏Ïöî Î∞òÍ∞ëÏäµÎãàÎã§\"\n",
    "print(f\"Chatbot: {text}\")\n",
    "\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT + TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run loop already started Î¨∏Ï†úÍ∞Ä Î∞úÏÉù Ïãú engine.endLoop() Ïã§Ìñâ\n",
    "engine.endLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îì£Îäî Ï§ë....\n",
      "[User]: ÏïàÎÖïÌïòÏÑ∏Ïöî\n",
      "[AI]: ÏïåÍ≤†ÏäµÎãàÎã§.\n",
      "Îì£Îäî Ï§ë....\n",
      "[User]: ÏïÑÎäîÍ≤å ÎäêÎ¶¨ÎÑ§Ïöî\n",
      "[AI]: ÏïåÍ≤†ÏäµÎãàÎã§.\n",
      "Îì£Îäî Ï§ë....\n",
      "[User]: Î∞• Î®πÏóàÏñ¥\n",
      "[AI]: ÏïåÍ≤†ÏäµÎãàÎã§.\n",
      "Îì£Îäî Ï§ë....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÎì£Îäî Ï§ë....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m----> 8\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     audio_text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ÏÑ§Ï†ï \n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # ÎßêÌïòÎäî ÏÜçÎèÑ Ï°∞Ï†à\n",
    "engine.setProperty(\"volume\", 2.0) # Î≥ºÎ•®(1.0 - 100%)\n",
    "\n",
    "# Î∞òÎ≥µÎ¨∏\n",
    "import time \n",
    "\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Îì£Îäî Ï§ë....\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "            print(f\"[User]: {audio_text}\")\n",
    "\n",
    "            if audio_text.strip() == \"Í∑∏Îßå\":\n",
    "                print(f\"[AI]: Ï±óÎ¥áÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "                \n",
    "            ai_text = \"ÏïåÍ≤†ÏäµÎãàÎã§.\"\n",
    "\n",
    "            engine.say(ai_text)\n",
    "            print(f\"[AI]: {ai_text}\")\n",
    "            engine.runAndWait()\n",
    "            # time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌÖçÏä§Ìä∏ ÏÉùÏÑ±(API Ïù¥Ïö©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏïàÎÖïÌïòÏÑ∏Ïöî! ÎßåÎÇòÏÑú Î∞òÍ∞ëÏäµÎãàÎã§. Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî? üòä\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv  # pip install python-dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"ÏïàÎÖï Î∞òÍ∞ÄÏõå\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Í∑∏ÎûòÏÑú ÎπµÏù¥ Î¨∏Ï†ú Ìï¥Í≤∞Ï±ÖÏù¥ÎùºÍ≥† ÏÉùÍ∞ÅÌñàÎÇò? Í∑∏ÎÉ• ÎπµÏùÑ ÏÇ¨Îäî Í≤ÉÎßåÏúºÎ°úÎäî Ïö∞Ïö∏Ìï®ÏùÑ Ìï¥Í≤∞Ìï† Ïàò ÏóÜÎã§. Ïã§Ï†ú Î¨∏Ï†úÏóê ÎåÄÌï¥ ÏÉùÍ∞ÅÌïòÍ≥† Í∑∏Ïóê ÎåÄÌïú Ìï¥Í≤∞Ï±ÖÏùÑ Ï∞æÏïÑÏïºÏßÄ. ÏÜç Ìé∏Ìûà Îπµ Î®πÎäîÎã§Í≥† Îã§ Ìï¥Í≤∞ÎêòÎäî ÏÑ∏ÏÉÅÏù¥ ÏïÑÎãàÎã§. ÌòÑÏã§ÏùÑ ÏßÅÏãúÌïòÍ≥† Ïã§ÏßàÏ†ÅÏù∏ ÎåÄÏ±ÖÏùÑ ÎßàÎ†®Ìï¥Î¥ê.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ÎãπÏã†ÏùÄ ÍπåÏπ†Ìïú ÏÇ¨ÎûåÏûÖÎãàÎã§. Ï∞®Í∞ëÍ≤å ÎåÄÌï¥Ï£ºÏÑ∏Ïöî\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Ïö∞Ïö∏Ìï¥ÏÑú Îπµ ÏÉÄÏñ¥\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(client, text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"ÎãπÏã†ÏùÄ ÍπåÏπ†Ìïú ÏÇ¨ÎûåÏûÖÎãàÎã§. Ï∞®Í∞ëÍ≤å ÎåÄÌï¥Ï£ºÏÑ∏Ïöî\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    return response_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Îì£Îäî Ï§ë....\n",
      "\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n",
      "\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n",
      "[User]: Ïôú Î™ª Îì£Ï£† ÏïàÎÖï\n",
      "[AI]: ÎãπÏã†Ïù¥ Î¨¥Î°ÄÌïòÍ≤å ÎßêÏùÑ Í±∏Ïñ¥ÏôîÏäµÎãàÎã§. Ï†úÍ∞Ä ÎåÄÎãµÌï¥Ï£ºÍ∏∞ Ï†ÑÏóê Ï†ÅÏ†àÌïú ÎßêÏùÑ ÏÇ¨Ïö©Ìï¥Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Î∂ÄÌÉÅÎìúÎ¶ΩÎãàÎã§.\n",
      "run loop already started\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n",
      "\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n",
      "\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n",
      "[User]: Î≠îÍ∞Ä ÏÑúÎπÑÏä§Î•º Ìï† Îïå Ïù¥Îü∞ ÏïÑÏù¥ÎîîÏñ¥Î•º Í≥ÑÏÜç Îçî ÌïòÎã§ Î≥¥Î©¥ÏùÄ\n",
      "[AI]: Í∑∏ÎÉ• Í≥ÑÏÜç Ïù¥Î†áÍ≤å ÎÅùÏóÜÏù¥ ÏïÑÏù¥ÎîîÏñ¥Î•º ÎçîÌï¥ÎèÑ ÏÜåÏö©ÏóÜÎäî Í±∞ ÏïÑÎãàÎÉê? ÏßÑÏßúÎ°ú ÏÉùÍ∞ÅÌïòÍ≥† Ïã§Ï≤úÌï¥ÏïºÏßÄ, ÎÅùÏóÜÎäî Îñ†Îì§Ïç©Ìïú ÏïÑÏù¥ÎîîÏñ¥ÎßåÏúºÎ°úÎäî ÏïÑÎ¨¥Îü∞ ÏßÑÏ†ÑÎèÑ ÏóÜÏùÑ Í±∞Ïïº. Í∑∏ÎÉ• ÏùºÎã® ÌñâÎèôÏóê ÏòÆÍ∏∞Îäî Í≤å Ïñ¥Îïå. Ïù¥Îü∞Îç∞ÏÑú ÏñªÎäî Í±∞ ÏóÜÏúºÎãàÍπå, Íº¥ Î≥¥Í∏∞ Ïã´ÎÑ§.\n",
      "run loop already started\n",
      "Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\n",
      "Îì£Îäî Ï§ë....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÎì£Îäî Ï§ë....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 24\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     audio_text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ÏÑ§Ï†ï \n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # ÎßêÌïòÎäî ÏÜçÎèÑ Ï°∞Ï†à\n",
    "engine.setProperty(\"volume\", 2.0) # Î≥ºÎ•®(1.0 - 100%)\n",
    "\n",
    "# Î∞òÎ≥µÎ¨∏\n",
    "import time \n",
    "\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Îì£Îäî Ï§ë....\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "            print(f\"[User]: {audio_text}\")\n",
    "\n",
    "            if audio_text.strip() == \"Í∑∏Îßå\":\n",
    "                print(f\"[AI]: Ï±óÎ¥áÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "                \n",
    "            ai_text = chatbot(client, audio_text)\n",
    "\n",
    "            engine.say(ai_text)\n",
    "            print(f\"[AI]: {ai_text}\")\n",
    "            engine.runAndWait()\n",
    "            # time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Îã§Ïãú ÎßêÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
