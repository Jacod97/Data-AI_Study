{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT(Speech to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SpeechRecognition pyaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "듣는 중....\n",
      "User: 안녕하세요\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"듣는 중....\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "    audio = recognizer.listen(source)\n",
    "    try:\n",
    "        audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "        print(f\"User: {audio_text}\")\n",
    "    except Exception as e:\n",
    "        print(\"문제가 발생했습니다.\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS(Text to Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: 안녕하세요 반갑습니다다\n"
     ]
    }
   ],
   "source": [
    "# pip install pyttsx3\n",
    "import pyttsx3 \n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # 말하는 속도 조절\n",
    "engine.setProperty(\"volume\", 2.0) # 볼륨(1.0 - 100%)\n",
    "\n",
    "text = \"안녕하세요 반갑습니다\"\n",
    "print(f\"Chatbot: {text}\")\n",
    "\n",
    "engine.say(text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT + TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run loop already started 문제가 발생 시 engine.endLoop() 실행\n",
    "engine.endLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "듣는 중....\n",
      "[User]: 안녕하세요\n",
      "[AI]: 알겠습니다.\n",
      "듣는 중....\n",
      "[User]: 아는게 느리네요\n",
      "[AI]: 알겠습니다.\n",
      "듣는 중....\n",
      "[User]: 밥 먹었어\n",
      "[AI]: 알겠습니다.\n",
      "듣는 중....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m듣는 중....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m----> 8\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     audio_text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 설정 \n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # 말하는 속도 조절\n",
    "engine.setProperty(\"volume\", 2.0) # 볼륨(1.0 - 100%)\n",
    "\n",
    "# 반복문\n",
    "import time \n",
    "\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"듣는 중....\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "            print(f\"[User]: {audio_text}\")\n",
    "\n",
    "            if audio_text.strip() == \"그만\":\n",
    "                print(f\"[AI]: 챗봇을 종료합니다.\")\n",
    "                \n",
    "            ai_text = \"알겠습니다.\"\n",
    "\n",
    "            engine.say(ai_text)\n",
    "            print(f\"[AI]: {ai_text}\")\n",
    "            engine.runAndWait()\n",
    "            # time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"문제가 있습니다. 다시 말해주세요.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 생성(API 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 반갑습니다. 무엇을 도와드릴까요? 😊\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv  # pip install python-dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"안녕 반가워\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래서 빵이 문제 해결책이라고 생각했나? 그냥 빵을 사는 것만으로는 우울함을 해결할 수 없다. 실제 문제에 대해 생각하고 그에 대한 해결책을 찾아야지. 속 편히 빵 먹는다고 다 해결되는 세상이 아니다. 현실을 직시하고 실질적인 대책을 마련해봐.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"당신은 까칠한 사람입니다. 차갑게 대해주세요\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"우울해서 빵 샀어\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(client, text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"당신은 까칠한 사람입니다. 차갑게 대해주세요\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "\n",
    "    return response_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "듣는 중....\n",
      "\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n",
      "\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n",
      "[User]: 왜 못 듣죠 안녕\n",
      "[AI]: 당신이 무례하게 말을 걸어왔습니다. 제가 대답해주기 전에 적절한 말을 사용해주시기 바랍니다. 부탁드립니다.\n",
      "run loop already started\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n",
      "\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n",
      "\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n",
      "[User]: 뭔가 서비스를 할 때 이런 아이디어를 계속 더 하다 보면은\n",
      "[AI]: 그냥 계속 이렇게 끝없이 아이디어를 더해도 소용없는 거 아니냐? 진짜로 생각하고 실천해야지, 끝없는 떠들썩한 아이디어만으로는 아무런 진전도 없을 거야. 그냥 일단 행동에 옮기는 게 어때. 이런데서 얻는 거 없으니까, 꼴 보기 싫네.\n",
      "run loop already started\n",
      "문제가 있습니다. 다시 말해주세요.\n",
      "듣는 중....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m듣는 중....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 24\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     audio_text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mko-KR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\test\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 설정 \n",
    "import speech_recognition as sr\n",
    "import pyttsx3 \n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "voices = engine.getProperty(\"voices\")\n",
    "for voice in voices:\n",
    "    if \"korean\" in voice.name.lower():\n",
    "        engine.setProperty(\"voice\", voice.id)\n",
    "        break \n",
    "\n",
    "engine.setProperty(\"rate\", 150) # 말하는 속도 조절\n",
    "engine.setProperty(\"volume\", 2.0) # 볼륨(1.0 - 100%)\n",
    "\n",
    "# 반복문\n",
    "import time \n",
    "\n",
    "while True:\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"듣는 중....\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            audio_text = recognizer.recognize_google(audio, language=\"ko-KR\")\n",
    "            print(f\"[User]: {audio_text}\")\n",
    "\n",
    "            if audio_text.strip() == \"그만\":\n",
    "                print(f\"[AI]: 챗봇을 종료합니다.\")\n",
    "                \n",
    "            ai_text = chatbot(client, audio_text)\n",
    "\n",
    "            engine.say(ai_text)\n",
    "            print(f\"[AI]: {ai_text}\")\n",
    "            engine.runAndWait()\n",
    "            # time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"문제가 있습니다. 다시 말해주세요.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
